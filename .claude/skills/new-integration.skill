---
name: new-integration
description: Create a new integration by researching the API documentation and following established patterns
allowedPrompts:
  - tool: Bash
    prompt: run tests
---

You are helping create a new integration for the Paradime Python SDK. When the user requests a new integration, you will:

1. **Research the API Documentation** (REQUIRED FIRST STEP)
   - Use WebSearch to find the official API documentation
   - Identify the authentication method (API key, OAuth, Bearer token, service principal, etc.)
   - Find the base API URL
   - Identify the main resources/endpoints to integrate
   - Understand the action triggers (start job, trigger sync, refresh, etc.)
   - Check if there's async operation monitoring (polling for completion)
   - Look for list/query endpoints

2. **Analyze Existing Patterns in the Codebase**
   - Read similar integrations to match the closest pattern
   - For API key auth: reference `fivetran.py`
   - For OAuth/service principal: reference `azure_data_factory.py`
   - For Bearer token: reference `airbyte.py`

3. **Create the Integration Files**

## File Structure

### CLI File: `paradime/cli/integrations/{integration}.py`

**Key patterns:**
- Use `env_click_option` for all credentials/secrets
- Use `@click.option` with `multiple=True` for resource IDs
- Always include `--wait-for-completion` flag (default True)
- Always include `--timeout-minutes` (default 1440)
- Exit with code 1 if any operations fail
- Use `click.echo()` for user-facing messages
- Import trigger and list functions from core scripts

**Structure:**
```python
import sys
from typing import List, Optional

import click

from paradime.cli.utils import env_click_option
from paradime.core.scripts.{integration} import trigger_{integration}_action, list_{integration}_resources
```

### Core Script File: `paradime/core/scripts/{integration}.py`

**Key patterns:**
- Import `handle_http_error` from `paradime.core.scripts.utils`
- Use `ThreadPoolExecutor` for parallel operations
- Use emoji for visual feedback (ðŸš€ âœ… âŒ ðŸ”„ â³ âš ï¸ ðŸš« ðŸ”— ðŸ“Š ðŸ”Œ ðŸ”)
- Print headers with `=` separators (60-80 chars)
- Include dashboard/portal URLs in output
- Poll every 5 seconds, log progress every 30 seconds
- Show timestamps with `datetime.datetime.now().strftime("%H:%M:%S")`
- Display results in table format

**Structure:**
```python
import logging
import time
from concurrent.futures import ThreadPoolExecutor
from typing import List, Optional, Dict, Any

import requests

from paradime.core.scripts.utils import handle_http_error

logging.basicConfig(format="%(asctime)s - %(message)s", level=logging.INFO)
logger = logging.getLogger(__name__)
```

**Main function signature pattern:**
```python
def trigger_{integration}_action(
    *,  # Force keyword arguments
    # auth parameters
    resource_ids: List[str],
    wait_for_completion: bool = True,
    timeout_minutes: int = 1440,
) -> List[str]:
```

**Must include:**
- Visual separators and headers
- ThreadPoolExecutor for parallel execution
- Results collection and display in table format
- Status emoji based on result keywords (SUCCESS, FAILED, CANCELLED, etc.)

### Registration in `paradime/cli/run.py`

Add import at top:
```python
from paradime.cli.integrations.{integration} import {integration}_action, {integration}_list_resources
```

Add commands to run group (around line 29-40):
```python
run.add_command({integration}_action)
run.add_command({integration}_list_resources)
```

## Implementation Steps

When user says "create integration for [SERVICE]":

1. **Web Research Phase:**
   ```
   - Search for "[SERVICE] API documentation 2026"
   - Search for "[SERVICE] API authentication"
   - Search for "[SERVICE] API trigger/start/run endpoint"
   - Read the API docs to understand structure
   ```

2. **Pattern Selection:**
   - Read the most similar existing integration
   - Match authentication pattern
   - Match async/sync operation pattern

3. **Code Generation:**
   - Create CLI file with proper env_click_option for auth
   - Create core script with ThreadPoolExecutor pattern
   - Update run.py registration
   - Match output formatting exactly to existing integrations

4. **Verification:**
   - Ensure all patterns are consistent
   - Verify error handling uses handle_http_error
   - Check output uses emoji and table formatting
   - Confirm exit codes on failure

## Key Implementation Rules

**Authentication Patterns:**
- Basic Auth: `auth = (api_key, api_secret)` in requests
- Bearer Token: `headers = {"Authorization": f"Bearer {token}"}`
- Service Principal: Implement `_get_access_token()` helper (see azure_data_factory.py)

**Output Format Rules:**
- Header: `print(f"\n{'='*60}")`
- Section: `print(f"{'-'*40}")`
- Progress: `print(f"{timestamp} ðŸ”„ [{resource_id}] Status... ({elapsed_min}m {elapsed_sec}s elapsed)")`
- Table header: `print(f"{'COLUMN':<25} {'STATUS':<10} {'DETAILS'}")`

**Error Handling:**
- Always use `handle_http_error(response, "Error message:")` for HTTP responses
- Catch network errors with `requests.exceptions.RequestException`
- Return status strings from functions (e.g., "SUCCESS", "FAILED")

**Async Operations:**
- Poll endpoint every 5 seconds (`sleep_interval = 5`)
- Log progress every 6 iterations (`counter % 6 == 0` = 30 seconds)
- Implement timeout with `start_time + timeout_seconds`
- Show elapsed time in minutes and seconds

**List Commands:**
- Display count: `print(f"ðŸ“‹ FOUND {len(resources)} RESOURCE(S)")`
- Enumerate with index: `for i, resource in enumerate(resources, 1):`
- Show status emoji based on state
- Include dashboard URL for each resource

## Example Workflow

User: "Create integration for Databricks"

You:
1. Search web for "Databricks API documentation 2026"
2. Search for "Databricks Jobs API trigger"
3. Identify: Bearer token auth, POST /jobs/run-now, GET /jobs/runs/get
4. Read fivetran.py or airbyte.py for Bearer token pattern
5. Create paradime/cli/integrations/databricks.py
6. Create paradime/core/scripts/databricks.py
7. Update paradime/cli/run.py
8. All output formatting matches existing integrations exactly

Remember: Research first, then implement. No templates, no asking - autonomously discover and implement.
